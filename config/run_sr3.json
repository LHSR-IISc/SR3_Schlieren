{
    "name": "Schlieren",
    "phase": "train", // train or val --> val is for inference on a trained model
    "gpu_ids": [
        0
    ],
    "path": { //set the path
        "log": "logs",
        "tb_logger": "tb_logger",
        "results": "results",
        "checkpoint": "checkpoint",
        "resume_state": null // training from scratch
        // "resume_state": "experiments/Schlieren_230417_103038/checkpoint/I50000_E396" // --> path of trained model in case of inference or also resumed training
    },
    "datasets": {
        "train": {
            "name": "Schlieren", // name for experiment
            "mode": "HR", // in case no corresponding LR images available, keep it as "HR"; keep "LRHR" if corresponding LR & HR images available
            "dataroot": "train_dir", // folder in SR3/ where the processed training data is kept
            "datatype": "img", //lmdb or img, path of img files
            "l_resolution": 64, // low resolution need to super_resolution
            "r_resolution": 256, // high resolution
            "batch_size": 8,
            "num_workers": 4, // manages how many workers will put data into the RAM
            "use_shuffle": true, // randomizer for training
            "data_len": -1 // -1 represents all data used in train; if specific number is put it will use that many images for training
        },
        "val": {
            "name": "Schlieren",
            "mode": "LRHR", // in case of doing inference with LR images, change this to LR
            "dataroot": "test_dir", // path where inference data is stored
            "datatype": "img", //lmdb or img, path of img files
            "l_resolution": 64,
            "r_resolution": 256,
            "data_len": -1 // data length in validation; like above -1 represents the whole dataset; when training keep it to the actual validation size
        }
    },
    "model": {
        "which_model_G": "sr3",
        "finetune_norm": false,
        "unet": {
            "in_channel": 2,
            "out_channel":1,
            "inner_channel": 32,
            "channel_multiplier": [
                1,
                2,
                4,
                8
                // 8
            ],
            "attn_res": [
                16
            ],
            "res_blocks": 2,
            "dropout": 0.4
        }, // controls the U-Net parameters // change "in_channel" to 6 in case of RGB image --. also make corresponding change in "diffusion" section below in the "channels" setting
        "beta_schedule": { // controls beta schedule; the available ones can be accessed from SR3/model/sr3_modules/diffusion.py
            "train": {
                "schedule": "cosine",
                "n_timestep": 1500,
                "linear_start": 1e-6,
                "linear_end": 1e-2
            },
            "val": {
                "schedule": "cosine",
                "n_timestep": 500,
                "linear_start": 1e-6,
                "linear_end": 1e-2
            }
        },
        "diffusion": {
            "image_size": 256,
            "channels": 1, //sample channel; use 3 for RGB images
            "conditional": true // unconditional generation or unconditional generation(super_resolution)
        }
    },
    "train": {
        "n_iter": 50000, // total number of desired updates
        "val_freq": 1000, // interval after which model will produce vlaidaiton images
        "save_checkpoint_freq": 2000, // number of updates after which model is stored
        "print_freq": 50, // number of updates after which the loss value is printed on terminal
        "optimizer": {
            "type": "adam",
            "lr": 5e-6
        },
        "ema_scheduler": { // not used now
            "step_start_ema": 5000,
            "update_ema_every": 1,
            "ema_decay": 0.9999
        }
    },
    "wandb": {
        "project": "Schlieren"
    } // used in case of logging with WandB
}